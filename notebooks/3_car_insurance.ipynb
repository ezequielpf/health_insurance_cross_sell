{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. The problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context\n",
    "\n",
    "Our client is an Insurance company that has provided Health Insurance to its customers. Now the company needs your help to build a model capable of predict if a policyholder (customers) from past year will also be interested in **Vehicle Insurance**, also provided by the company.\n",
    "\n",
    "A prediction model will help the company being more accurate in its communication strategy to reach out those customers most likely to purchase a vehicle insurance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "Supposing that the company does not have enough resources to contact every client in the data base, a good strategy would be creating a list of clients ordered by their propensity of being interested in Vehicle Insurance. Such strategy would allow the company to maximize the effort of reaching the potential clients in comparison to a randomized choice in a list.\n",
    "\n",
    "Let's say the company has a marketing budget to contact **25000** person.\n",
    "\n",
    "The purpose is to employ a Machine Learning model to order a list of clients, from the most interested in to the less one. Next, with that list it is possible to plot a Cumulative Gains Curve to evaluate the effectiveness of the model in comparison to a randomized choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "#sns.set_theme(style=\"darkgrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import TargetEncoder, StandardScaler, RobustScaler\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, f_classif\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, ConfusionMatrixDisplay\n",
    "\n",
    "#from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler, QuantileTransformer, PowerTransformer, RobustScaler, TargetEncoder\n",
    "#from sklearn.feature_selection import mutual_info_classif\n",
    "#\n",
    "#from sklearn.compose import ColumnTransformer\n",
    "#from sklearn.pipeline import Pipeline\n",
    "#\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#\n",
    "#from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split, cross_validate\n",
    "#from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "#\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def some_metrics(y_pred, y_true):\n",
    "    accuracy = accuracy_score(y_pred=y_pred, y_true=y_true)\n",
    "    precision = precision_score(y_pred=y_pred, y_true=y_true)\n",
    "    recall = recall_score(y_pred=y_pred, y_true=y_true)\n",
    "    f1 = f1_score(y_pred=y_pred, y_true=y_true)\n",
    "    print(f'Accuracy: {100*accuracy:.4f}%')\n",
    "    print(f'Precision: {100*precision:.4f}%')\n",
    "    print(f'Recall: {100*recall:.4f}%')\n",
    "    print(f'F1 score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data available at https://www.kaggle.com/datasets/anmolkumar/health-insurance-cross-sell-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/raw/train.csv'\n",
    "\n",
    "df_raw = pd.read_csv(filepath_or_buffer=PATH)\n",
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns description:\n",
    "\n",
    "* **id**                      Unique ID for the customer  \n",
    "* **Gender**                  Gender of the customer  \n",
    "* **Age**                     Age of the customer  \n",
    "* **Driving_License**         0 : Customer does not have DL, 1 : Customer already has DL  \n",
    "* **Region_Code** \t        Unique code for the region of the customer  \n",
    "* **Previously_Insured**\t    1 : Customer already has Vehicle Insurance, 0 : Customer doesn't have Vehicle Insurance  \n",
    "* **Vehicle_Age** \t        Age of the Vehicle  \n",
    "* **Vehicle_Damage** \t        1 : Customer got his/her vehicle damaged in the past. 0 : Customer didn't get his/her vehicle damaged in the past.  \n",
    "* **Annual_Premium** \t        The amount customer needs to pay as premium in the year  \n",
    "* **Policy_Sales_Channel** \tAnonymized Code for the channel of outreaching to the customer ie. Different Agents, Over Mail, Over Phone, In Person, etc.  \n",
    "* **Vintage** \t            Number of Days which customer has been associated with the company  \n",
    "* **Response** \t            1 : Customer is interested, 0 : Customer is not interested\n",
    "\n",
    "* Currency: Idian Rupee (Rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.columns = df_train.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of rows: {df.shape[0]}')\n",
    "print(f'Number of columns: {df.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## id column has no importance and can be removed\n",
    "#df_train.drop(columns=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "- Categorical variables:\n",
    "    - gender (object)\n",
    "    - driving license (int64)\n",
    "    - previously insured (int64)\n",
    "    - region code (float64)\n",
    "    - policy sales channel (float64)\n",
    "    - vehicle age (object)\n",
    "    - vehicle damage (object)\n",
    "    - response (int64)\n",
    "- Variable representing numerical variables:\n",
    "    - age\n",
    "    - annual premium\n",
    "    - vintage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform type of some categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Driving_License'] = df['Driving_License'].astype('category')\n",
    "#df['Previously_Insured'] = df['Previously_Insured'].astype('category')\n",
    "#df['Region_Code'] = df['Region_Code'].astype('category')\n",
    "#df['Policy_Sales_Channel'] = df['Policy_Sales_Channel'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values\n",
    "-> No missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicated\n",
    "-> The number of duplicates is low, so they were removed with no further investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = train_test_split(df, train_size=0.7, stratify=df['Response'], random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target variable\n",
    "-> Unbalanced target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df_train, x=df_train['Response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total of interested: {df_train[\"Response\"].value_counts(normalize=True)[1]*100:.2f}%')\n",
    "print(f'Total of not interested: {df_train[\"Response\"].value_counts(normalize=True)[0]*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = df_train[[\"Age\", \"Annual_Premium\", \"Vintage\"]].columns.tolist()\n",
    "#num_columns = df_train.select_dtypes(exclude=['object', 'category']).columns.tolist()\n",
    "#num_columns.pop(0)\n",
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[num_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(20, 10))\n",
    "sns.histplot(data=df_train, x='Age', hue='Response', bins=50, ax=ax[0][0])\n",
    "sns.histplot(data=df_train, x='Annual_Premium', bins=50, hue='Response', ax=ax[0][1])\n",
    "sns.histplot(data=df_train, x='Vintage', hue='Response', bins=50, ax=ax[1][0])\n",
    "sns.histplot(data=df_train, x='Region_Code', hue='Response', bins=50, ax=ax[1][1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_columns = df_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "cat_columns = df_train.drop(columns=num_columns).columns.tolist()\n",
    "cat_columns.pop(0)\n",
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "sns.countplot(data=df_train, x='Gender', hue='Response', ax=ax[0][0])\n",
    "sns.countplot(data=df_train, x='Vehicle_Age', hue='Response', ax=ax[0][1])\n",
    "sns.countplot(data=df_train, x='Vehicle_Damage', hue='Response', ax=ax[1][0])\n",
    "sns.countplot(data=df_train, x='Driving_License', hue='Response', ax=ax[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H1**: Individuals between 30 and 50 years old would be more likely to purchase a vehicle insurance.\n",
    "-> True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "between_30_50 = df_train.query('Age >= 30 & Age <= 50 & Response == 1').shape[0]\n",
    "below_30 = df_train.query('Age < 30 and Response == 1').shape[0]\n",
    "over_50 = df_train.query('Age > 50 and Response == 1').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux1 = pd.DataFrame({'below_30': [below_30],\n",
    "                     'between_30_50': [between_30_50],\n",
    "                     'over_50': [over_50]})\n",
    "aux1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=aux1)\n",
    "plt.title('Purchasing propensity by age group');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H2**: Women would be more interested in having vehicle insurance.\n",
    "-> False. 10,4% of total women would purchase compared to 13,8% of total men."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df_train, x='Gender')\n",
    "plt.title('Entries by gender');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result given in proportion by gender\n",
    "gender_count = pd.crosstab(df_train['Response'], df_train['Gender'], normalize='columns')\n",
    "gender_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "gender_count.plot(kind='bar', stacked=True, ax=ax)\n",
    "plt.xticks(rotation=0)\n",
    "plt.title('Interest by gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H3**: Individuals who already have driver license and got the vehicle damage in the past would be more interested in vehicle insurance.\n",
    "-> False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux3 = df_train.query('Driving_License == 1 & Vehicle_Damage == \"Yes\"')['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=aux3)\n",
    "plt.title('Purchasing propensity among people who Driving_License = 1 and Vehicle_Damage = Yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H4**: Individuals who already have vehicle insurance (previously insured) would not be interested in vehicle insurance.\n",
    "-> True. 99,91% of those who already have insurance would not purchase another one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=df_train['Response'], columns=df_train['Previously_Insured'], normalize='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H5**: Individuals who got the vehicle damaged and were not previously insured would be more interested in vehicle insurance.\n",
    "-> False. Even if not being insured, people who have vehicle damaged would not purschase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux5 = df_train.query('Vehicle_Damage == \"Yes\" & Previously_Insured == 0')['Response'].value_counts()\n",
    "sns.barplot(data=aux5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H6**: Individuals who own vehicle with more than two year would be more interested in vehicle insurance.\n",
    "-> FALSE. Ownners of vehicles between 1-2 years are the most interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux7 = pd.crosstab(index=df['Response'], columns=df['Vehicle_Age'])\n",
    "aux7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "aux7.plot(kind='bar', stacked=True, ax=ax)\n",
    "plt.xticks(rotation=0)\n",
    "plt.title('Propensity by vehicle age');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize=(18,5))\n",
    "sns.countplot(data=df_train, x=df_train['Gender'], hue=df_train['Response'], ax=ax[0])\n",
    "sns.countplot(data=df_train, x=df_train['Vehicle_Age'], hue=df_train['Response'], ax=ax[1])\n",
    "sns.countplot(data=df_train, x=df_train['Vehicle_Damage'], hue=df_train['Response'], ax=ax[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vehicle Damage = No --> almost everybody is not interested "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Policy sales channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = df_train.groupby('Policy_Sales_Channel')['Response'].sum().reset_index()\n",
    "aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = sns.histplot(data=df_train, x='Policy_Sales_Channel')\n",
    "ax = plt.plot(aux['Response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform vehicle_damage to binary\n",
    "df_train['Vehicle_Damage'] = df_train['Vehicle_Damage'].apply(lambda x: 0 if x=='No' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping gender --> Male:0, Female:1\n",
    "gender_map = {\"Male\": 0, \"Female\": 1}\n",
    "df_train[\"Gender\"] = df_train[\"Gender\"].map(gender_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite vehicle age\n",
    "#age_dict = {'1-2 Year': 'between_1_2',\n",
    "#            '< 1 Year': 'below_1',\n",
    "#            '> 2 Years': 'over_2'}\n",
    "\n",
    "age_dict = {'< 1 Year': 1,\n",
    "            '1-2 Year': 2,\n",
    "            '> 2 Years': 3}\n",
    "\n",
    "df_train['Vehicle_Age'] = df_train['Vehicle_Age'].map(age_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform type of some categorical features\n",
    "df_train[\"Gender\"] = df_train[\"Gender\"].astype(\"category\")\n",
    "df_train['Driving_License'] = df_train['Driving_License'].astype('category')\n",
    "df_train['Previously_Insured'] = df_train['Previously_Insured'].astype('category')\n",
    "df_train[\"Vehicle_Damage\"] = df_train[\"Vehicle_Damage\"].astype(\"category\")\n",
    "df_train['Region_Code'] = df_train['Region_Code'].astype('category')\n",
    "df_train['Policy_Sales_Channel'] = df_train['Policy_Sales_Channel'].astype('category')\n",
    "df_train[\"Response\"] = df_train[\"Response\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=\"Response\").copy()\n",
    "\n",
    "y_train = df_train['Response']\n",
    "\n",
    "print(f'Training dataframe shape: {df_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make column names lowercase\n",
    "X_train.columns = X_train.columns.str.lower()\n",
    "\n",
    "y_train.name = y_train.name.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = X_train.select_dtypes(exclude=['object', 'category']).columns.to_list()\n",
    "cat_columns = X_train.select_dtypes(include=['object', 'category']).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.dropna(inplace=True)\n",
    "#df_train.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1. One hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General function for One Hot Encoder\n",
    "#def one_hot_encoder(df_to_encode, feature_to_encode):\n",
    "#    encoder = OneHotEncoder(drop='if_binary')\n",
    "#    new_features = encoder.fit_transform(df_to_encode[feature_to_encode]).toarray()\n",
    "#    df_to_encode[encoder.get_feature_names_out()] = new_features\n",
    "#    df_to_encode.drop(columns=encoder.feature_names_in_[0], inplace=True)\n",
    "#    return df_to_encode, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender ---> OBS: Test dummy encoding\n",
    "#X_train, encoding_gender = one_hot_encoder(df_to_encode=X_train, feature_to_encode=['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driving license\n",
    "#X_train, encoding_license = one_hot_encoder(df_to_encode=X_train, feature_to_encode=['driving_license'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previously insured\n",
    "#X_train, encoding_insured = one_hot_encoder(df_to_encode=X_train, feature_to_encode=['previously_insured'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vehicle damage\n",
    "#X_train, encoding_damage = one_hot_encoder(df_to_encode=X_train, feature_to_encode=['vehicle_damage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vehicle age\n",
    "# OBS: Testar Ordinal Enconding ou Target Enconding\n",
    "#X_train, encoding_v_age = one_hot_encoder(df_to_encode=X_train, feature_to_encode=['vehicle_age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2. Target encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region code\n",
    "tar_enc_reg_code = TargetEncoder()\n",
    "X_train['region_code'] = tar_enc_reg_code.fit_transform(X=X_train[['region_code']], y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy sales channel\n",
    "tar_enc_pol_sales = TargetEncoder()\n",
    "X_train['policy_sales_channel'] = tar_enc_pol_sales.fit_transform(X=X_train[['policy_sales_channel']], y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[num_columns].hist(bins=50, figsize=(16,8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vintage - MinMax scaler,Standard scaler, Quantile transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#std_vintage = MinMaxScaler()\n",
    "std_vintage = StandardScaler()\n",
    "#std_vintage = QuantileTransformer()\n",
    "#std_vintage = PowerTransformer(method='box-cox')\n",
    "#std_vintage = RobustScaler()\n",
    "\n",
    "new_vintage = std_vintage.fit_transform(X_train[['vintage']])\n",
    "X_train['vintage'] = new_vintage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age - MinMax scaler, Standard scaler, Box-Cox or Quantile transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#std_age = MinMaxScaler()\n",
    "std_age = StandardScaler()\n",
    "#std_age = QuantileTransformer()\n",
    "#std_age = PowerTransformer(method='box-cox')\n",
    "#std_age = RobustScaler()\n",
    "\n",
    "#aux1 = X_train[['age']].transform(np.log1p)\n",
    "#new_age = std_age.fit_transform(aux1)\n",
    "new_age = std_age.fit_transform(X_train[['age']])\n",
    "X_train['age'] = new_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anual premium - Standard scaler, Robust scaler, Box-Cox or Quantile transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#std_vintage = MinMaxScaler()\n",
    "std_anual_pr = StandardScaler()\n",
    "#std_anual_pr = QuantileTransformer()\n",
    "#std_anual_pr = PowerTransformer(method='box-cox')\n",
    "#std_anual_pr = RobustScaler()\n",
    "\n",
    "aux1 = X_train[['annual_premium']].transform(np.log1p)\n",
    "new_anual_pr = std_anual_pr.fit_transform(aux1)\n",
    "#new_anual_pr = std_anual_pr.fit_transform(X_train[['annual_premium']])\n",
    "X_train['annual_premium'] = new_anual_pr\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(14,5))\n",
    "sns.histplot(data=df_train['Annual_Premium'], bins=50, ax=ax[0])\n",
    "sns.histplot(data=new_anual_pr, bins=50, ax=ax[1])\n",
    "ax[0].set_title('No scalling')\n",
    "ax[1].set_title('Some scalling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Validation dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform vehicle_damage to binary\n",
    "df_valid['Vehicle_Damage'] = df_valid['Vehicle_Damage'].apply(lambda x: 0 if x=='No' else 1)\n",
    "\n",
    "# Mapping gender --> Male:0, Female:1\n",
    "gender_map = {\"Male\": 0, \"Female\": 1}\n",
    "df_valid[\"Gender\"] = df_valid[\"Gender\"].map(gender_map)\n",
    "\n",
    "# Rewrite vehicle age\n",
    "age_dict = {'< 1 Year': 1,\n",
    "            '1-2 Year': 2,\n",
    "            '> 2 Years': 3}\n",
    "df_valid['Vehicle_Age'] = df_valid['Vehicle_Age'].map(age_dict)\n",
    "\n",
    "# Transform type of some categorical features\n",
    "df_valid[\"Gender\"] = df_valid[\"Gender\"].astype(\"category\")\n",
    "df_valid['Driving_License'] = df_valid['Driving_License'].astype('category')\n",
    "df_valid['Previously_Insured'] = df_valid['Previously_Insured'].astype('category')\n",
    "df_valid[\"Vehicle_Damage\"] = df_valid[\"Vehicle_Damage\"].astype(\"category\")\n",
    "df_valid['Region_Code'] = df_valid['Region_Code'].astype('category')\n",
    "df_valid['Policy_Sales_Channel'] = df_valid['Policy_Sales_Channel'].astype('category')\n",
    "df_valid[\"Response\"] = df_valid[\"Response\"].astype(\"category\")\n",
    "\n",
    "# id column has no importance and can be removed\n",
    "#df_valid.drop(columns=['id'], inplace=True)\n",
    "X_valid = df_valid.drop(columns=\"Response\").copy()\n",
    "y_valid = df_valid['Response']\n",
    "\n",
    "# Make column names lowercase\n",
    "X_valid.columns = X_valid.columns.str.lower()\n",
    "y_valid.name = y_valid.name.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_valid[encoding_gender.get_feature_names_out()] =encoding_gender.transform(X=X_valid[['gender']]).toarray()\n",
    "#X_valid.drop(columns=encoding_gender.feature_names_in_[0], inplace=True)\n",
    "#\n",
    "#X_valid[encoding_license.get_feature_names_out()] =encoding_license.transform(X=X_valid[['driving_license']]).toarray()\n",
    "#X_valid.drop(columns=encoding_license.feature_names_in_[0], inplace=True)\n",
    "#\n",
    "#X_valid[encoding_insured.get_feature_names_out()] =encoding_insured.transform(X=X_valid[['previously_insured']]).toarray()\n",
    "#X_valid.drop(columns=encoding_insured.feature_names_in_[0], inplace=True)\n",
    "#\n",
    "#X_valid[encoding_damage.get_feature_names_out()] =encoding_damage.transform(X=X_valid[['vehicle_damage']]).toarray()\n",
    "#X_valid.drop(columns=encoding_damage.feature_names_in_[0], inplace=True)\n",
    "#\n",
    "#X_valid[encoding_v_age.get_feature_names_out()] =encoding_v_age.transform(X=X_valid[['vehicle_age']]).toarray()\n",
    "#X_valid.drop(columns=encoding_v_age.feature_names_in_[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid['region_code'] = tar_enc_reg_code.transform(X=X_valid[['region_code']])\n",
    "\n",
    "X_valid['policy_sales_channel'] = tar_enc_pol_sales.transform(X=X_valid[['policy_sales_channel']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid['age'] = std_age.transform(X=X_valid[['age']])\n",
    "\n",
    "X_valid['vintage'] = std_vintage.transform(X=X_valid[['vintage']])\n",
    "\n",
    "X_valid['annual_premium'] = std_anual_pr.transform(X=X_valid[['annual_premium']].transform(np.log1p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_no_id = X_train.drop(columns=[\"id\"])\n",
    "X_valid_no_id = X_valid.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.1. Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = X_train.drop(columns=[\"id\"])\n",
    "aux = aux.join(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = aux.corr()\n",
    "plt.figure(figsize=(12,7))\n",
    "sns.heatmap(data=corr_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix[\"response\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.1. Tree-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_clf = RandomForestClassifier(n_estimators=400, random_state=seed, n_jobs=-1)\n",
    "feat_imp_clf.fit(X=X_train_no_id, y=y_train)\n",
    "\n",
    "tree_based_score = pd.DataFrame(data=feat_imp_clf.feature_importances_, index=X_train_no_id.columns,\n",
    "                                columns=['tree_based']).sort_values(by='tree_based', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_based_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=tree_based_score, y=tree_based_score.index, x='tree_based', kind='bar', aspect=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.1. Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_score = mutual_info_classif(X=X_train_no_id, y=y_train, random_state=seed, n_jobs=-1)\n",
    "mi_score = pd.DataFrame(data=mi_score, index=X_train_no_id.columns, columns=['mi_score']).sort_values(by='mi_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=mi_score, y=mi_score.index, x='mi_score', kind='bar', aspect=2)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Machine Learning Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics**:\n",
    "- Caution with accuracy because the target classes are unbalanced. There is much more people who are not interested in car insurence\n",
    "- It is important to indentify as many customers as possible who are interested in car insurance, even though the model makes some mistakes ==> Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Using all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train_no_id.columns.to_list()\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. Training models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select k-best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kbest_vs_score(model):\n",
    "    k_vs_score = []\n",
    "    for k in range(2, len(X_train_no_id.columns)+1):\n",
    "        selector = SelectKBest(score_func=f_classif, k=k)\n",
    "\n",
    "        X_train_2 = selector.fit_transform(X=X_train_no_id, y=y_train)\n",
    "        X_valid_2 = selector.transform(X=X_valid_no_id)\n",
    "\n",
    "        model_clf = model\n",
    "        model_clf.fit(X=X_train_2, y=y_train)\n",
    "        y_pred_model = model_clf.predict(X=X_valid_2)\n",
    "        y_pred_proba_model = model_clf.predict_proba(X=X_valid_2)\n",
    "        roc_model = roc_auc_score(y_score=y_pred_proba_model[:,1], y_true=y_valid)\n",
    "        accuracy = accuracy_score(y_pred=y_pred_model, y_true=y_valid)\n",
    "        precision = precision_score(y_true=y_valid, y_pred=y_pred_model)\n",
    "        recall = recall_score(y_true=y_valid, y_pred=y_pred_model)\n",
    "\n",
    "        k_vs_score.append(recall)\n",
    "\n",
    "        print(f\"Number of features: {k}\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "        print(f\"ROC: {roc_model}\")\n",
    "        print(30*\"-\")\n",
    "\n",
    "        sns.lineplot(k_vs_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_reg_clf = LogisticRegression(class_weight='balanced', random_state=seed)\n",
    "#kbest_vs_score(model=log_reg_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_clf = LogisticRegression(class_weight='balanced', random_state=seed)\n",
    "log_reg_clf.fit(X=X_train[features], y=y_train)\n",
    "y_pred_log_reg = log_reg_clf.predict(X=X_valid[features])\n",
    "y_pred_proba_log_reg = log_reg_clf.predict_proba(X=X_valid[features])\n",
    "roc_log_reg = roc_auc_score(y_score=y_pred_proba_log_reg[:,1], y_true=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf_clf = RandomForestClassifier(n_estimators=150, n_jobs=-1, random_state=42)\n",
    "#kbest_vs_score(model=rf_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=150, n_jobs=-1, random_state=42)\n",
    "rf_clf.fit(X=X_train[features], y=y_train)\n",
    "y_pred_rf = rf_clf.predict(X=X_valid[features])\n",
    "y_pred_proba_rf = rf_clf.predict_proba(X=X_valid[features])\n",
    "roc_rf = roc_auc_score(y_score=y_pred_proba_rf[:,1], y_true=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hgb_clf = HistGradientBoostingClassifier(random_state=42)\n",
    "#kbest_vs_score(model=hgb_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgb_clf = HistGradientBoostingClassifier(random_state=42)\n",
    "hgb_clf.fit(X=X_train[features], y=y_train)\n",
    "y_pred_hgb = hgb_clf.predict(X=X_valid[features])\n",
    "y_pred_proba_hgb = hgb_clf.predict_proba(X=X_valid[features])\n",
    "roc_hgb = roc_auc_score(y_score=y_pred_proba_hgb[:,1], y_true=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(models):\n",
    "\n",
    "    results = {'Model': [],\n",
    "               'Accuracy': [],\n",
    "               'Precision': [],\n",
    "               'Recall': [],\n",
    "               'ROC_AUC': []}\n",
    "\n",
    "    for name, pred in models.items():\n",
    "        results['Model'].append(name)\n",
    "        results['Accuracy'].append(accuracy_score(y_pred=pred[0], y_true=y_valid))\n",
    "        results['Precision'].append(precision_score(y_pred=pred[0], y_true=y_valid))\n",
    "        results['Recall'].append(recall_score(y_pred=pred[0], y_true=y_valid))\n",
    "        results[\"ROC_AUC\"].append(pred[1])\n",
    "\n",
    "    results = pd.DataFrame(results).set_index('Model')\n",
    "    results.index.names = [None]\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'Logistic Regression': [y_pred_log_reg, roc_log_reg],\n",
    "          'Random Forest': [y_pred_rf, roc_rf],\n",
    "          'HGBoost': [y_pred_hgb, roc_hgb]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = metrics(models)\n",
    "results.style.highlight_max(color='green', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,4, figsize=(20, 5))\n",
    "fig.suptitle('Confusion Matrix')\n",
    "ConfusionMatrixDisplay.from_predictions(y_true=y_valid, y_pred=y_pred_log_reg, labels=log_reg_clf.classes_, ax=ax[0], cmap='Blues',colorbar=False)\n",
    "#ConfusionMatrixDisplay.from_predictions(y_true=y_valid, y_pred=y_pred_knn, labels=knn_clf.classes_, ax=ax[1], cmap='Blues',colorbar=False)\n",
    "ConfusionMatrixDisplay.from_predictions(y_true=y_valid, y_pred=y_pred_rf, labels=rf_clf.classes_, ax=ax[2], cmap='Blues',colorbar=False)\n",
    "ConfusionMatrixDisplay.from_predictions(y_true=y_valid, y_pred=y_pred_hgb, labels=hgb_clf.classes_, ax=ax[3], cmap='Blues',colorbar=False)\n",
    "ax[0].set_title('Logistic Regression')\n",
    "ax[1].set_title('KNN')\n",
    "ax[2].set_title('Random Forest')\n",
    "ax[3].set_title('HGBoosting')\n",
    "for axes in ax.flatten():\n",
    "    axes.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics @ K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propensity score - probability of each customer being interested in car insurance\n",
    "aux = pd.concat([X_valid, y_valid], axis=1)\n",
    "#aux['score'] = y_pred_proba_log_reg[:, 1].tolist()\n",
    "aux['score'] = y_pred_proba_hgb[:, 1].tolist()\n",
    "\n",
    "# Sort clients by propensity score\n",
    "aux = aux.sort_values('score', ascending=False)\n",
    "\n",
    "aux = aux[[\"id\", 'response', 'score']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 25000                   # number of calls\n",
    "n = K / X_valid.shape[0]      # percentage of data base represented by the number of calls\n",
    "\n",
    "print(f'K = {K} represents {n * 100:.2f}% of the validation data base')\n",
    "\n",
    "# Precision Top K\n",
    "aux['precision_at_k'] = aux['response'].astype(int).cumsum() / (aux.index.values + 1)\n",
    "precision_at_k = aux.loc[K, 'precision_at_k']\n",
    "print(f'Precision @ K: {precision_at_k * 100:.2f}%')\n",
    "\n",
    "# Recall Top K\n",
    "aux['recall_at_k'] = aux['response'].astype(int).cumsum() / aux['response'].astype(int).sum()\n",
    "recall_at_k = aux.loc[K, 'recall_at_k']\n",
    "print(f'Recall @ K: {recall_at_k * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(14,5))\n",
    "\n",
    "# Gains curve --> Recall (gain) as a function of percentage of sample\n",
    "skplt.metrics.plot_cumulative_gain(y_probas=y_pred_proba_log_reg, y_true=y_valid, ax=ax[0])\n",
    "ax[0].vlines(x=n, ymin=0, ymax=recall_at_k, linestyles='dashed', colors='purple')\n",
    "ax[0].hlines(y=recall_at_k, xmin=0, xmax=n, linestyles='dashed', colors='purple')\n",
    "ax[0].hlines(y=n, xmin=0, xmax=n, linestyles='dashed', colors='purple')\n",
    "\n",
    "# Lift curvr --> Lift represents the percentage of customers interested in car insurance as a function of the percentage sample \n",
    "skplt.metrics.plot_lift_curve(y_probas=y_pred_proba_log_reg, y_true=y_valid, ax=ax[1])\n",
    "ax[1].vlines(x=n, ymin=0, ymax=recall_at_k/n, linestyles='dashed', color='purple')\n",
    "ax[1].hlines(y=recall_at_k/n, xmin=0, xmax=n, linestyles='dashed', color='purple')\n",
    "ax[1].set_xlim(0.05, 1)\n",
    "ax[1].set_ylim(0.5, 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline vs. ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_class_1 = y_valid.value_counts()[1]\n",
    "\n",
    "random_selection = df_valid[[\"id\", \"Response\"]].sample(n=K)\n",
    "total_random = random_selection[\"Response\"].value_counts()[1]\n",
    "\n",
    "total_ml_model = aux.iloc[:K, 0:2][\"response\"].value_counts()[1]\n",
    "\n",
    "avg_insurance = 1000.00     # hypothetical anual average cost of vehicle insurance in US$\n",
    "cost_per_contact = 1.00     # hypothetical cost per contact in US$\n",
    "\n",
    "random_cost = total_random * cost_per_contact\n",
    "ML_cost = total_ml_model * cost_per_contact\n",
    "\n",
    "random_revenue = avg_insurance * total_random\n",
    "ML_revenue = avg_insurance * total_ml_model\n",
    "\n",
    "summary = {'Recall': [n, recall_at_k],\n",
    "           'Number of interests': [total_random, total_ml_model],\n",
    "           'Contact per sale': [f'{K / total_random:.2f}', f'{K / total_ml_model:.2f}'],\n",
    "           'Cost of contacts (US$)': [random_cost, ML_cost],\n",
    "           'Revenue (US$)': [random_revenue, ML_revenue],\n",
    "           \"Profit (US$):\": [random_revenue - random_cost, ML_revenue - ML_cost],\n",
    "           'Gain (%)': ['-', f'{((ML_revenue-random_revenue)/random_revenue)*100:.2f}']}\n",
    "\n",
    "df_summary = pd.DataFrame(index=['Random', 'ML model'], data=summary)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_list = [y_pred_proba_log_reg, y_pred_proba_knn, y_pred_proba_rf, y_pred_proba_hgb, ]\n",
    "skplt.metrics.plot_calibration_curve(y_valid, probas_list, list(models.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strategy**\n",
    "- Reach the highest number of customers with potencial of purchasing insurance\n",
    "- Recall must be increased in order to contact as many interested as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
