{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. The problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context\n",
    "\n",
    "Our client is an Insurance company that has provided Health Insurance to its customers. Now the company needs your help to build a model capable of predict if a policyholder (customers) from past year will also be interested in **Vehicle Insurance**, also provided by the company.\n",
    "\n",
    "A prediction model will help the company being more accurate in its communication strategy to reach out those customers most likely to purchase a vehicle insurance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "Supposing that the company does not have enough resources to contact every client in the data base, a good strategy would be creating a list of clients ordered by their propensity of being interested in Vehicle Insurance. Such strategy would allow the company to maximize the effort of reaching the potential clients in comparison to a randomized choice in a list.\n",
    "\n",
    "Let's say the company has a marketing budget to contact **25000** person.\n",
    "\n",
    "The purpose is to employ a Machine Learning model to order a list of clients, from the most interested in to the less one. Next, with that list it is possible to plot a Cumulative Gains Curve to evaluate the effectiveness of the model in comparison to a randomized choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler, QuantileTransformer, PowerTransformer, RobustScaler, TargetEncoder\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split, cross_validate\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def some_metrics(y_pred, y_true):\n",
    "    accuracy = accuracy_score(y_pred=y_pred, y_true=y_true)\n",
    "    precision = precision_score(y_pred=y_pred, y_true=y_true)\n",
    "    recall = recall_score(y_pred=y_pred, y_true=y_true)\n",
    "    f1 = f1_score(y_pred=y_pred, y_true=y_true)\n",
    "    print(f'Accuracy: {100*accuracy:.4f}%')\n",
    "    print(f'Precision: {100*precision:.4f}%')\n",
    "    print(f'Recall: {100*recall:.4f}%')\n",
    "    print(f'F1 score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/ezequiel/Documentos/Comunidade_DS/car_insurance_sell/data/raw/train.csv'\n",
    "\n",
    "df_raw = pd.read_csv(filepath_or_buffer=PATH)\n",
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns description:\n",
    "\n",
    "* **id**                      Unique ID for the customer  \n",
    "* **Gender**                  Gender of the customer  \n",
    "* **Age**                     Age of the customer  \n",
    "* **Driving_License**         0 : Customer does not have DL, 1 : Customer already has DL  \n",
    "* **Region_Code** \t        Unique code for the region of the customer  \n",
    "* **Previously_Insured**\t    1 : Customer already has Vehicle Insurance, 0 : Customer doesn't have Vehicle Insurance  \n",
    "* **Vehicle_Age** \t        Age of the Vehicle  \n",
    "* **Vehicle_Damage** \t        1 : Customer got his/her vehicle damaged in the past. 0 : Customer didn't get his/her vehicle damaged in the past.  \n",
    "* **Annual_Premium** \t        The amount customer needs to pay as premium in the year  \n",
    "* **Policy_Sales_Channel** \tAnonymized Code for the channel of outreaching to the customer ie. Different Agents, Over Mail, Over Phone, In Person, etc.  \n",
    "* **Vintage** \t            Number of Days which customer has been associated with the company  \n",
    "* **Response** \t            1 : Customer is interested, 0 : Customer is not interested\n",
    "\n",
    "* Currency: Idian Rupee (Rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.columns = df_train.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of rows: {df.shape[0]}')\n",
    "print(f'Number of columns: {df.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## id column has no importance and can be removed\n",
    "#df_train.drop(columns=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "- Categorical variables:\n",
    "    - gender (object)\n",
    "    - driving license (int64)\n",
    "    - previously insured (int64)\n",
    "    - region code (float64)\n",
    "    - policy sales channel (float64)\n",
    "    - vehicle age (object)\n",
    "    - vehicle damage (object)\n",
    "    - response (int64)\n",
    "- Variable representing numerical variables:\n",
    "    - age\n",
    "    - annual premium\n",
    "    - vintage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform type of some categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Driving_License'] = df['Driving_License'].astype('category')\n",
    "df['Previously_Insured'] = df['Previously_Insured'].astype('category')\n",
    "df['Region_Code'] = df['Region_Code'].astype('category')\n",
    "df['Policy_Sales_Channel'] = df['Policy_Sales_Channel'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values\n",
    "-> No missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicated\n",
    "-> The number of duplicates is low, so they were removed with no further investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target variable\n",
    "-> Unbalanced target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x=df['Response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total of interested: {df[\"Response\"].value_counts(normalize=True)[1]*100:.2f}%')\n",
    "print(f'Total of not interested: {df[\"Response\"].value_counts(normalize=True)[0]*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = df.select_dtypes(exclude=['object', 'category']).columns.tolist()\n",
    "num_columns.pop(0)\n",
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(20, 10))\n",
    "sns.histplot(data=df, x='Age', hue='Response', bins=50, ax=ax[0][0])\n",
    "sns.histplot(data=df, x='Annual_Premium', bins=50, hue='Response', ax=ax[0][1])\n",
    "sns.histplot(data=df, x='Vintage', hue='Response', bins=50, ax=ax[1][0])\n",
    "sns.histplot(data=df, x='Region_Code', hue='Response', bins=50, ax=ax[1][1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "sns.countplot(data=df, x='Gender', hue='Response', ax=ax[0][0])\n",
    "sns.countplot(data=df, x='Vehicle_Age', hue='Response', ax=ax[0][1])\n",
    "sns.countplot(data=df, x='Vehicle_Damage', hue='Response', ax=ax[1][0])\n",
    "sns.countplot(data=df, x='Driving_License', hue='Response', ax=ax[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H1**: Individuals between 30 and 50 years old would be more likely to purchase a vehicle insurance.\n",
    "-> True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "between_30_50 = df.query('Age >= 30 & Age <= 50 & Response == 1').shape[0]\n",
    "below_30 = df.query('Age < 30 and Response == 1').shape[0]\n",
    "over_50 = df.query('Age > 50 and Response == 1').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux1 = pd.DataFrame({'below_30': [below_30],\n",
    "                     'between_30_50': [between_30_50],\n",
    "                     'over_50': [over_50]})\n",
    "aux1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=aux1)\n",
    "plt.title('Purchasing propensity by age group');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H2**: Women would be more interested in having vehicle insurance.\n",
    "-> False. 10,4% of total women would purchase compared to 13,8% of total men."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x='Gender')\n",
    "plt.title('Entries by gender');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result given in proportion by gender\n",
    "gender_count = pd.crosstab(df['Response'], df['Gender'], normalize='columns')\n",
    "gender_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "gender_count.plot(kind='bar', stacked=True, ax=ax)\n",
    "plt.xticks(rotation=0)\n",
    "plt.title('Interest by gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H3**: Individuals who already have driver license and got the vehicle damage in the past would be more interested in vehicle insurance.\n",
    "-> False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux3 = df.query('Driving_License == 1 & Vehicle_Damage == \"Yes\"')['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=aux3)\n",
    "plt.title('Purchasing propensity among people who Driving_License = 1 and Vehicle_Damage = Yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H4**: Individuals who already have vehicle insurance (previously insured) would not be interested in vehicle insurance.\n",
    "-> True. 99,91% of those who already have insurance would not purchase another one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=df['Response'], columns=df['Previously_Insured'], normalize='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H5**: Individuals who got the vehicle damaged and were not previously insured would be more interested in vehicle insurance.\n",
    "-> False. Even if not being insured, people who have vehicle damaged would not purschase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux5 = df.query('Vehicle_Damage == \"Yes\" & Previously_Insured == 0')['Response'].value_counts()\n",
    "sns.barplot(data=aux5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H6**: Individuals who own vehicle with more than two year would be more interested in vehicle insurance.\n",
    "-> FALSE. Ownners of vehicles between 1-2 years are the most interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux7 = pd.crosstab(index=df['Response'], columns=df['Vehicle_Age'])\n",
    "aux7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "aux7.plot(kind='bar', stacked=True, ax=ax)\n",
    "plt.xticks(rotation=0)\n",
    "plt.title('Propensity by vehicle age');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize=(18,5))\n",
    "sns.countplot(data=df, x=df['Gender'], hue=df['Response'], ax=ax[0])\n",
    "sns.countplot(data=df, x=df['Vehicle_Age'], hue=df['Response'], ax=ax[1])\n",
    "sns.countplot(data=df, x=df['Vehicle_Damage'], hue=df['Response'], ax=ax[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vehicle Damage = No --> almost everybody is not interested "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Policy sales channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = df.groupby('Policy_Sales_Channel')['Response'].sum().reset_index()\n",
    "aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = sns.histplot(data=df, x='Policy_Sales_Channel')\n",
    "ax = plt.plot(aux['Response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Spliting data into train and validation dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = train_test_split(df, train_size=0.8, stratify=df['Response'], random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns='Response').copy()\n",
    "X_valid = df_valid.drop(columns='Response').copy()\n",
    "\n",
    "y_train = df_train['Response']\n",
    "y_valid = df_valid['Response']\n",
    "\n",
    "print(f'Training dataframe shape: {df_train.shape}')\n",
    "print(f'Validation dataframe shape: {df_valid.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make column names lowercase\n",
    "X_train.columns = X_train.columns.str.lower()\n",
    "X_valid.columns = X_valid.columns.str.lower()\n",
    "y_train.name = y_train.name.lower()\n",
    "y_valid.name = y_valid.name.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id column has no importance and can be removed\n",
    "X_train.drop(columns=['id'], inplace=True)\n",
    "X_valid.drop(columns=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite vehicle age\n",
    "age_dict = {'1-2 Year': 'between_1_2',\n",
    "            '< 1 Year': 'below_1',\n",
    "            '> 2 Years': 'over_2'}\n",
    "\n",
    "X_train['vehicle_age'] = X_train['vehicle_age'].map(age_dict)\n",
    "X_valid['vehicle_age'] = X_valid['vehicle_age'].map(age_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = X_train.select_dtypes(exclude=['object', 'category']).columns.to_list()\n",
    "cat_columns = X_train.select_dtypes(include=['object', 'category']).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.dropna(inplace=True)\n",
    "#df_train.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transform vehicle_damage to numeric\n",
    "#df_train['vehicle_damage'] = df_train['vehicle_damage'].apply(lambda x: 0 if x=='No' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1. One hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General function for One Hot Encoder\n",
    "def one_hot_encoder(df_to_encode, feature_to_encode):\n",
    "    encoder = OneHotEncoder(drop='if_binary')\n",
    "    new_features = encoder.fit_transform(df_to_encode[feature_to_encode]).toarray()\n",
    "    df_to_encode[encoder.get_feature_names_out()] = new_features\n",
    "    df_to_encode.drop(columns=encoder.feature_names_in_[0], inplace=True)\n",
    "    return df_to_encode, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender ---> OBS: Test dummy encoding\n",
    "X_train, encoding_gender = one_hot_encoder(df_to_encode=X_train, feature_to_encode=['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driving license\n",
    "X_train, encoding_license = one_hot_encoder(df_to_encode=X_train, feature_to_encode=['driving_license'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previously insured\n",
    "X_train, encoding_insured = one_hot_encoder(df_to_encode=X_train, feature_to_encode=['previously_insured'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vehicle damage\n",
    "X_train, encoding_damage = one_hot_encoder(df_to_encode=X_train, feature_to_encode=['vehicle_damage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vehicle age\n",
    "X_train, encoding_v_age = one_hot_encoder(df_to_encode=X_train, feature_to_encode=['vehicle_age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2. Target encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region code\n",
    "tar_enc_reg_code = TargetEncoder()\n",
    "X_train['region_code'] = tar_enc_reg_code.fit_transform(X=X_train[['region_code']], y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy sales channel\n",
    "tar_enc_pol_sales = TargetEncoder()\n",
    "X_train['policy_sales_channel'] = tar_enc_pol_sales.fit_transform(X=X_train[['policy_sales_channel']], y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[num_columns].hist(bins=50, figsize=(16,8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vintage - MinMax scaler,Standard scaler, Quantile transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#std_vintage = MinMaxScaler()\n",
    "std_vintage = StandardScaler()\n",
    "#std_vintage = QuantileTransformer()\n",
    "#std_vintage = PowerTransformer(method='box-cox')\n",
    "#std_vintage = RobustScaler()\n",
    "\n",
    "new_vintage = std_vintage.fit_transform(X_train[['vintage']])\n",
    "X_train['vintage'] = new_vintage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(14,5))\n",
    "sns.histplot(data=X_train['vintage'], bins=50, ax=ax[0])\n",
    "sns.histplot(data=new_vintage, bins=50, ax=ax[1])\n",
    "ax[0].set_title('No scalling')\n",
    "ax[1].set_title('Some scalling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age - MinMax scaler, Standard scaler, Box-Cox or Quantile transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#std_age = MinMaxScaler()\n",
    "std_age = StandardScaler()\n",
    "#std_age = QuantileTransformer()\n",
    "#std_age = PowerTransformer(method='box-cox')\n",
    "#std_age = RobustScaler()\n",
    "\n",
    "#aux1 = X_train[['age']].transform(np.log1p)\n",
    "#new_age = std_age.fit_transform(aux1)\n",
    "new_age = std_age.fit_transform(X_train[['age']])\n",
    "X_train['age'] = new_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(14,5))\n",
    "sns.histplot(data=X_train['age'], bins=50, ax=ax[0])\n",
    "sns.histplot(data=new_age, bins=50, ax=ax[1])\n",
    "ax[0].set_title('No scalling')\n",
    "ax[1].set_title('Some scalling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anual premium - Standard scaler, Robust scaler, Box-Cox or Quantile transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#std_vintage = MinMaxScaler()\n",
    "std_anual_pr = StandardScaler()\n",
    "#std_anual_pr = QuantileTransformer()\n",
    "#std_anual_pr = PowerTransformer(method='box-cox')\n",
    "#std_anual_pr = RobustScaler()\n",
    "\n",
    "aux1 = X_train[['annual_premium']].transform(np.log1p)\n",
    "new_anual_pr = std_anual_pr.fit_transform(aux1)\n",
    "#new_anual_pr = std_anual_pr.fit_transform(X_train[['annual_premium']])\n",
    "X_train['annual_premium'] = new_anual_pr\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(14,5))\n",
    "sns.histplot(data=df_train['Annual_Premium'], bins=50, ax=ax[0])\n",
    "sns.histplot(data=new_anual_pr, bins=50, ax=ax[1])\n",
    "ax[0].set_title('No scalling')\n",
    "ax[1].set_title('Some scalling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Validation dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid[encoding_gender.get_feature_names_out()] =encoding_gender.transform(X=X_valid[['gender']]).toarray()\n",
    "X_valid.drop(columns=encoding_gender.feature_names_in_[0], inplace=True)\n",
    "\n",
    "X_valid[encoding_license.get_feature_names_out()] =encoding_license.transform(X=X_valid[['driving_license']]).toarray()\n",
    "X_valid.drop(columns=encoding_license.feature_names_in_[0], inplace=True)\n",
    "\n",
    "X_valid[encoding_insured.get_feature_names_out()] =encoding_insured.transform(X=X_valid[['previously_insured']]).toarray()\n",
    "X_valid.drop(columns=encoding_insured.feature_names_in_[0], inplace=True)\n",
    "\n",
    "X_valid[encoding_damage.get_feature_names_out()] =encoding_damage.transform(X=X_valid[['vehicle_damage']]).toarray()\n",
    "X_valid.drop(columns=encoding_damage.feature_names_in_[0], inplace=True)\n",
    "\n",
    "X_valid[encoding_v_age.get_feature_names_out()] =encoding_v_age.transform(X=X_valid[['vehicle_age']]).toarray()\n",
    "X_valid.drop(columns=encoding_v_age.feature_names_in_[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid['region_code'] = tar_enc_reg_code.transform(X=X_valid[['region_code']])\n",
    "\n",
    "X_valid['policy_sales_channel'] = tar_enc_pol_sales.transform(X=X_valid[['policy_sales_channel']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid['age'] = std_age.transform(X=X_valid[['age']])\n",
    "\n",
    "X_valid['vintage'] = std_vintage.transform(X=X_valid[['vintage']])\n",
    "\n",
    "X_valid['annual_premium'] = std_anual_pr.transform(X=X_valid[['annual_premium']].transform(np.log1p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Machine Learning Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Model trainning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_clf.fit(X=X_train, y=y_train)\n",
    "y_pred_log_reg = log_reg_clf.predict(X=X_valid)\n",
    "y_pred_proba_log_reg = log_reg_clf.predict_proba(X=X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf.fit(X=X_train, y=y_train)\n",
    "y_pred_knn = knn_clf.predict(X=X_valid)\n",
    "y_pred_proba_knn = knn_clf.predict_proba(X=X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, n_jobs=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf.fit(X=X_train, y=y_train)\n",
    "y_pred_rf = rf_clf.predict(X=X_valid)\n",
    "y_pred_proba_rf = rf_clf.predict_proba(X=X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3. HGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgb_clf = HistGradientBoostingClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgb_clf.fit(X=X_train, y=y_train)\n",
    "y_pred_hgb = hgb_clf.predict(X=X_valid)\n",
    "y_pred_proba_hgb = hgb_clf.predict_proba(X=X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(models):\n",
    "\n",
    "    results = {'Model': [],\n",
    "               'Accuracy': [],\n",
    "               'Precision': [],\n",
    "               'Recall': []}\n",
    "\n",
    "    for name, pred in models.items():\n",
    "        results['Model'].append(name)\n",
    "        results['Accuracy'].append(accuracy_score(y_pred=pred, y_true=y_valid))\n",
    "        results['Precision'].append(precision_score(y_pred=pred, y_true=y_valid))\n",
    "        results['Recall'].append(recall_score(y_pred=pred, y_true=y_valid))\n",
    "\n",
    "    results = pd.DataFrame(results).set_index('Model')\n",
    "    results.index.names = [None]\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'Logistic Regression': y_pred_log_reg,\n",
    "          'KNN': y_pred_knn,\n",
    "          'Random Forest': y_pred_rf,\n",
    "          'HGBoost': y_pred_hgb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = metrics(models)\n",
    "results.style.highlight_max(color='green', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(15, 12))\n",
    "skplt.metrics.plot_roc(y_probas=y_pred_proba_log_reg, y_true=y_valid, plot_macro=False, plot_micro=False, title='Linear Regression', classes_to_plot=1, ax=ax[0][0])\n",
    "skplt.metrics.plot_roc(y_probas=y_pred_proba_knn, y_true=y_valid, plot_macro=False, plot_micro=False, title='KNN', classes_to_plot=1, ax=ax[0][1])\n",
    "skplt.metrics.plot_roc(y_probas=y_pred_proba_rf, y_true=y_valid, plot_macro=False, plot_micro=False, title='Random Forest', classes_to_plot=1, ax=ax[1][0])\n",
    "skplt.metrics.plot_roc(y_probas=y_pred_proba_hgb, y_true=y_valid, plot_macro=False, plot_micro=False, title='HGBoosting', classes_to_plot=1, ax=ax[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
